---
title: APIã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ä½¿ç”¨ã‚¬ã‚¤ãƒ‰
description: OmniAI APIè©³ç´°ä½¿ç”¨èª¬æ˜ã€å…¨ãƒ¢ãƒ‡ãƒ«ã®å‘¼ã³å‡ºã—æ–¹æ³•ã¨é«˜åº¦æ©Ÿèƒ½è¨­å®šã‚’å«ã‚€
---

## ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹èª¬æ˜

OmniAIã¯çµ±ä¸€ã•ã‚ŒãŸAPIã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹æ¨™æº–ã‚’æä¾›ã—ã€**OpenAI APIå½¢å¼ã¨å®Œå…¨äº’æ›**ã€ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ãªåˆ‡ã‚Šæ›¿ãˆã‚’ã‚µãƒãƒ¼ãƒˆã€‚1ã¤ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚¢ãƒ‰ãƒ¬ã‚¹ã§OpenAIã€Claudeã€Geminiã€Midjourneyç­‰ã‚’å«ã‚€å…¨ä¸»è¦AIãƒ¢ãƒ‡ãƒ«ã«ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ã€‚

### ğŸŒ åŸºæœ¬è¨­å®š

#### APIã‚¢ãƒ‰ãƒ¬ã‚¹
å…ƒã®OpenAI APIã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’OmniAIã‚¢ãƒ‰ãƒ¬ã‚¹ã«ç½®æ›ï¼š
```
å…ƒã‚¢ãƒ‰ãƒ¬ã‚¹: https://api.openai.com
æ–°ã‚¢ãƒ‰ãƒ¬ã‚¹: https://api.pandalla.ai
```

#### èº«å…ƒèªè¨¼
[ãƒˆãƒ¼ã‚¯ãƒ³ç®¡ç†ãƒšãƒ¼ã‚¸](https://api.pandalla.ai/token)ã§å°‚ç”¨APIã‚­ãƒ¼ã‚’ç”Ÿæˆ

> ğŸ’¡ **é‡è¦ãªãƒ’ãƒ³ãƒˆ**: ãƒˆãƒ¼ã‚¯ãƒ³ç”Ÿæˆæ™‚ã¯ã‚°ãƒ«ãƒ¼ãƒ—é¸æŠã«æ³¨æ„ã€ç•°ãªã‚‹ã‚°ãƒ«ãƒ¼ãƒ—ã¯ç•°ãªã‚‹ã‚µãƒ¼ãƒ“ã‚¹ãƒãƒ£ãƒãƒ«ã¨èª²é‡‘æ¨™æº–ã«å¯¾å¿œ

![ãƒˆãƒ¼ã‚¯ãƒ³ç®¡ç†ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹](/token_index.jpg)

---

## ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### ğŸ“‹ å‰ææ¡ä»¶
å…¬å¼OpenAIãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‚ç…§ã—ã¦é–‹ç™ºç’°å¢ƒè¨­å®šï¼š
- [Python SDK](https://github.com/openai/openai-python) 
- [Node.js SDK](https://github.com/openai/openai-node)

### ğŸ Python SDK

#### ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
```bash
pip install openai
```

#### åŸºæœ¬å‘¼ã³å‡ºã—ä¾‹
```python
from openai import OpenAI

# ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
client = OpenAI(
    base_url="https://api.pandalla.ai/v1",
    api_key="sk-your-omniai-api-key"  # ã‚ãªãŸã®ã‚­ãƒ¼ã«ç½®æ›
)

# ãƒãƒ£ãƒƒãƒˆãƒªã‚¯ã‚¨ã‚¹ãƒˆç™ºè¡Œ
response = client.chat.completions.create(
    model="gpt-4o-mini",
    max_tokens=16384,
    messages=[
        {"role": "user", "content": "ã“ã‚“ã«ã¡ã¯ã€OmniAIãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã‚’ç´¹ä»‹ã—ã¦ãã ã•ã„"}
    ]
)

print(response.choices[0].message.content)
```

### ğŸŒ HTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆä¾‹

#### æ¨™æº–ãƒãƒ£ãƒƒãƒˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
```bash
curl --request POST \
    --url https://api.pandalla.ai/v1/chat/completions \
    --header 'Authorization: Bearer sk-your-omniai-api-key' \
    --header 'Content-Type: application/json' \
    --data '{
        "model": "gpt-4o-mini",
        "max_tokens": 1024,
        "temperature": 0.8,
        "top_p": 1,
        "presence_penalty": 0,
        "messages": [
            {
                "role": "system",
                "content": "ã‚ãªãŸã¯æŠ€è¡“çš„ãªè³ªå•ã«ç­”ãˆã‚‹ã®ãŒå¾—æ„ãªå°‚é–€çš„ãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
            },
            {
                "role": "user", 
                "content": "å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã¨ã¯ä½•ã‹ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚"
            }
        ]
    }'
```

#### ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ç”»åƒç†è§£
```bash
curl https://api.pandalla.ai/v1/chat/completions \
    --header 'Authorization: Bearer sk-your-omniai-api-key' \
    --header 'Content-Type: application/json' \
    --data '{
        "model": "gpt-4-vision-preview",
        "max_tokens": 1024,
        "messages": [
            {
                "role": "system",
                "content": "ã‚ãªãŸã¯Tailwind CSSã®ä½¿ç”¨ã«é•·ã‘ãŸå°‚é–€çš„ãªãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰é–‹ç™ºã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™"
            },
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": "ã“ã®ç”»åƒã«åŸºã¥ã„ã¦å¯¾å¿œã™ã‚‹Webãƒšãƒ¼ã‚¸ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã€Tailwind CSSã‚¹ã‚¿ã‚¤ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„"
                    },
                    {
                        "type": "image_url", 
                        "image_url": {
                            "url": "data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD/..."
                        }
                    }
                ]
            }
        ]
    }'
```

---

## ãƒ¢ãƒ‡ãƒ«ã‚µãƒãƒ¼ãƒˆ

### ğŸ¤– ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒ¢ãƒ‡ãƒ«

#### OpenAIã‚·ãƒªãƒ¼ã‚º
å…¨OpenAIå…¬å¼ãƒ¢ãƒ‡ãƒ«ã‚’ã‚µãƒãƒ¼ãƒˆã€åŒã˜å‘¼ã³å‡ºã—æ–¹å¼ã‚’ä½¿ç”¨ï¼š
- `gpt-4o`, `gpt-4o-mini` - æœ€æ–°ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«
- `gpt-4-turbo`, `gpt-4` - é«˜æ€§èƒ½æ¨è«–ãƒ¢ãƒ‡ãƒ«  
- `gpt-3.5-turbo` - çµŒæ¸ˆå®Ÿç”¨ãƒ¢ãƒ‡ãƒ«
- `o1-preview`, `o1-mini` - æ¨è«–æœ€é©åŒ–ãƒ¢ãƒ‡ãƒ«

#### Anthropic Claude
OpenAI APIå½¢å¼ã¨å®Œå…¨äº’æ›ã€ãƒ¢ãƒ‡ãƒ«åã‚’å¤‰æ›´ã™ã‚‹ã ã‘ï¼š
```python
response = client.chat.completions.create(
    model="claude-3-5-sonnet-20241022",  # Claudeãƒ¢ãƒ‡ãƒ«ä½¿ç”¨
    messages=[{"role": "user", "content": "ã“ã‚“ã«ã¡ã¯"}]
)
```

ã‚µãƒãƒ¼ãƒˆã•ã‚Œã‚‹Claudeãƒ¢ãƒ‡ãƒ«ï¼š
- `claude-3-5-sonnet-20241022` - æœ€æ–°Sonnetãƒ¢ãƒ‡ãƒ«
- `claude-3-5-haiku-20241022` - é«˜é€Ÿå¿œç­”ãƒ¢ãƒ‡ãƒ«
- `claude-3-opus-20240229` - æœ€å¼·æ€§èƒ½ãƒ¢ãƒ‡ãƒ«

#### Google Gemini
åŒæ§˜ã«OpenAI APIå½¢å¼ã®å‘¼ã³å‡ºã—ã‚’ã‚µãƒãƒ¼ãƒˆï¼š
```python
response = client.chat.completions.create(
    model="gemini-1.5-flash-002",  # Geminiãƒ¢ãƒ‡ãƒ«ä½¿ç”¨
    messages=[{"role": "user", "content": "Hello Gemini"}]
)
```

---

## é«˜åº¦æ©Ÿèƒ½

### ğŸ” Geminiå°‚ç”¨æ©Ÿèƒ½

#### ãƒãƒƒãƒˆæ¤œç´¢
Geminiãƒ¢ãƒ‡ãƒ«ã«ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œç´¢æ©Ÿèƒ½ã‚’æœ‰åŠ¹åŒ–ï¼š

```bash
curl -X POST https://api.pandalla.ai/v1/chat/completions \
    --header 'Content-Type: application/json' \
    --header 'Authorization: Bearer sk-your-omniai-api-key' \
    --data '{
        "model": "gemini-1.5-flash-002",
        "messages": [
            {"role": "user", "content": "2024å¹´æœ€æ–°ã®AIæŠ€è¡“ç™ºå±•ãƒˆãƒ¬ãƒ³ãƒ‰ã¯ä½•ã§ã™ã‹ï¼Ÿ"}
        ],
        "tools": [
            {
                "type": "function",
                "function": {
                    "name": "googleSearch",
                    "description": "ç¾åœ¨ã®æƒ…å ±ã‚’Webã§æ¤œç´¢",
                    "parameters": {}
                }
            }
        ]
    }'
```

#### ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œ
Geminiã®ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œèƒ½åŠ›ã‚’æœ‰åŠ¹åŒ–ï¼š

```bash
curl -X POST https://api.pandalla.ai/v1/chat/completions \
    --header 'Content-Type: application/json' \
    --header 'Authorization: Bearer sk-your-omniai-api-key' \
    --data '{
        "model": "gemini-1.5-flash-002",
        "messages": [
            {"role": "user", "content": "ãƒ•ã‚£ãƒœãƒŠãƒƒãƒæ•°åˆ—ã®æœ€åˆã®20é …ã‚’è¨ˆç®—ã—ã€ã‚°ãƒ©ãƒ•ã‚’æã„ã¦ãã ã•ã„"}
        ],
        "tools": [
            {
                "type": "function",
                "function": {
                    "name": "codeExecution",
                    "description": "Pythonã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œ",
                    "parameters": {}
                }
            }
        ]
    }'
```

---

## æ¨è«–ãƒ¢ãƒ‡ãƒ«ç‰¹åˆ¥èª¬æ˜

### ğŸ§  OpenAIæ¨è«–ãƒ¢ãƒ‡ãƒ«
`o1`ã€`o1-mini`ã€`o3`ã€`o3-mini`ã€`o4-mini`ç­‰æ¨è«–ãƒ¢ãƒ‡ãƒ«ã®ç‰¹åˆ¥è¨­å®šï¼š

#### ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
- âœ… **è‡ªå‹•æ¨è«–æœ‰åŠ¹**: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã‚ªãƒ³ã€æ‰‹å‹•ã§ã‚ªãƒ•ã«ã§ããªã„
- âš ï¸ **ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åˆ¶é™**: `temperature`ã€`top_k`ã€`top_p`ç­‰ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ã‚µãƒãƒ¼ãƒˆã—ãªã„
- ğŸ“ **æ¨è«–ãƒ—ãƒ­ã‚»ã‚¹**: å†…éƒ¨æ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«è¿”ã•ã‚Œãªã„

#### æ¨è«–å¼·åº¦åˆ¶å¾¡
```python
response = client.chat.completions.create(
    model="o1-preview",
    messages=[{"role": "user", "content": "ã“ã®è¤‡é›‘ãªæ•°å­¦å•é¡Œã‚’è§£ã„ã¦ãã ã•ã„..."}],
    reasoning={
        "effort": "high"  # ã‚ªãƒ—ã‚·ãƒ§ãƒ³: low, medium, high
    }
)
```

#### æ³¨æ„äº‹é …
- ğŸ”„ **Tokenè¨­å®š**: å¤§ãã„`max_tokens`å€¤ã®è¨­å®šã‚’æ¨å¥¨
- âš¡ **å¿œç­”æ™‚é–“**: æ¨è«–ãƒ¢ãƒ‡ãƒ«ã®å¿œç­”æ™‚é–“ã¯é•·ã„ã®ã§ã€ãŠå¾…ã¡ãã ã•ã„
- ğŸ“‹ **ã‚³ãƒ³ãƒ†ãƒ³ãƒ„åˆè¦**: 400ã‚¨ãƒ©ãƒ¼ãŒè¿”ã•ã‚Œã‚‹å ´åˆã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒä½¿ç”¨è¦ç¯„ã«åˆè‡´ã™ã‚‹ã‹ç¢ºèª

### ğŸ­ Claudeæ¨è«–ãƒ¢ãƒ‡ãƒ«
Claudeæ¨è«–ãƒ¢ãƒ‡ãƒ«ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§**æ¨è«–ã‚ªãƒ•**ã€æ‰‹å‹•ã§æœ‰åŠ¹åŒ–ãŒå¿…è¦ï¼š

#### æ¨è«–æœ‰åŠ¹åŒ–
```python
response = client.chat.completions.create(
    model="claude-3-5-sonnet-20241022",
    max_tokens=4096,
    messages=[{"role": "user", "content": "ã“ã®è¤‡é›‘ãªå•é¡Œã‚’åˆ†æã—ã¦ãã ã•ã„..."}],
    reasoning={
        "effort": "medium",     # æ¨è«–å¼·åº¦: low/medium/high
        "max_tokens": 2048      # æ¨è«–å°‚ç”¨tokenæ•°é‡
    }
)
```

#### æ¨è«–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¬æ˜
- `effort`: æ¨è«–æ·±åº¦åˆ¶å¾¡ã€ç·`max_tokens`ã®20%/50%/80%ã«å¯¾å¿œ
- `max_tokens`: æ¨è«–ãƒ—ãƒ­ã‚»ã‚¹å°‚ç”¨tokenã€ç·`max_tokens`ã‚’è¶…ãˆã¦ã¯ã„ã‘ãªã„
- âš ï¸ **ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åˆ¶é™**: æ¨è«–æœ‰åŠ¹åŒ–å¾Œã€`temperature`ç­‰ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯1ã®ã¿è¨­å®šå¯èƒ½

### ğŸ”® Geminiæ¨è«–ãƒ¢ãƒ‡ãƒ«

#### Gemini 2.5-flash
```python
response = client.chat.completions.create(
    model="gemini-2.5-flash",
    messages=[{"role": "user", "content": "æ·±åº¦åˆ†æ..."}],
    reasoning={
        "max_tokens": 2048  # æœ€å°1024ã€0ã«è¨­å®šã™ã‚‹ã¨æ¨è«–ã‚’ã‚ªãƒ•ã«
    }
)
```

#### Gemini 2.5-pro
```python
response = client.chat.completions.create(
    model="gemini-2.5-pro", 
    messages=[{"role": "user", "content": "è¤‡é›‘ãªæ¨è«–ã‚¿ã‚¹ã‚¯..."}],
    reasoning={
        "max_tokens": 4096  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã‚ªãƒ³ã€ã‚ªãƒ•ã«ã§ããªã„ã€æœ€å°1024
    }
)
```

---

## èª²é‡‘èª¬æ˜

### ğŸ“Š èª²é‡‘ãƒ¢ãƒ¼ãƒ‰

#### TokenåŸºã¥ãèª²é‡‘
ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒ¢ãƒ‡ãƒ«ï¼ˆOpenAIã€Claudeã€Geminiç­‰ï¼‰ã«é©ç”¨ï¼š
```
å®Ÿéš›è²»ç”¨ = Tokenæ•°é‡ Ã— ãƒ¢ãƒ‡ãƒ«å…¬å¼å˜ä¾¡ Ã— ãƒãƒ£ãƒãƒ«å‰²å¼• Ã— ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¬ãƒ™ãƒ«å‰²å¼•
```

#### å›æ•°ãƒ™ãƒ¼ã‚¹èª²é‡‘  
ç”Ÿæˆé¡ãƒ¢ãƒ‡ãƒ«ï¼ˆMidjourneyã€Sunoç­‰ï¼‰ã«é©ç”¨ï¼š
```
å®Ÿéš›è²»ç”¨ = å‘¼ã³å‡ºã—å›æ•° Ã— ãƒ¢ãƒ‡ãƒ«å›ºå®šå˜ä¾¡ Ã— ãƒãƒ£ãƒãƒ«å‰²å¼• Ã— ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¬ãƒ™ãƒ«å‰²å¼•
```

### ğŸ’° å„ªé‡æ”¿ç­–
- ğŸ¢ **ä¼æ¥­é¡§å®¢**: å•†ç”¨å„ªé‡ä¾¡æ ¼ã¨å°‚ç”¨é«˜é€Ÿãƒãƒ£ãƒãƒ«ã‚’äº«å—
- ğŸ“ˆ **å¤§ç”¨é‡é¡§å®¢**: è‡ªå‹•ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¬ãƒ™ãƒ«ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰ã€ã‚ˆã‚Šä½ã„å‰²å¼•ã‚’äº«å—
- ğŸ”„ **å‹•çš„ä¾¡æ ¼**: å¸‚å ´çŠ¶æ³ã¨ã‚³ã‚¹ãƒˆã«å¿œã˜ãŸåˆç†çš„ä¾¡æ ¼èª¿æ•´

---

## ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

### âš¡ æ€§èƒ½æœ€é©åŒ–

#### 1. åˆç†çš„ãªãƒ¢ãƒ‡ãƒ«é¸æŠ
```python
# ç°¡å˜ãªã‚¿ã‚¹ã‚¯ã«ã¯çµŒæ¸ˆãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
simple_response = client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[{"role": "user", "content": "ã“ã®æ–‡ã‚’ç¿»è¨³ã—ã¦ãã ã•ã„"}]
)

# è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã«ã¯é«˜ç´šãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
complex_response = client.chat.completions.create(
    model="gpt-4o",
    messages=[{"role": "user", "content": "ã“ã®è¤‡é›‘ãªãƒ“ã‚¸ãƒã‚¹ãƒ¬ãƒãƒ¼ãƒˆã‚’åˆ†æã—ã¦ãã ã•ã„"}]
)
```

#### 2. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–
```python
# âŒ éåŠ¹ç‡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
bad_prompt = "ã‚³ãƒ¼ãƒ‰ã‚’æ›¸ãã®ã‚’æ‰‹ä¼ã£ã¦"

# âœ… åŠ¹ç‡çš„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
good_prompt = """
å°‚é–€çš„ãªPythoné–‹ç™ºè€…ã¨ã—ã¦ã€ä»¥ä¸‹ã‚’æ‰‹ä¼ã£ã¦ãã ã•ã„ï¼š
1. CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã™ã‚‹é–¢æ•°ã‚’æ›¸ã
2. ã‚¨ãƒ©ãƒ¼å‡¦ç†ã¨ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã‚’å«ã‚€  
3. è©³ç´°ãªã‚³ãƒ¡ãƒ³ãƒˆã¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ–‡å­—åˆ—ã‚’è¿½åŠ 
4. å‡¦ç†çµæœã®çµ±è¨ˆæƒ…å ±ã‚’è¿”ã™
"""
```

#### 3. ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¿œç­”
```python
# ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¿œç­”ã‚’æœ‰åŠ¹ã«ã—ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“ã‚’å‘ä¸Š
stream = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[{"role": "user", "content": "é•·ã„è¨˜äº‹ã‚’æ›¸ã„ã¦ãã ã•ã„"}],
    stream=True
)

for chunk in stream:
    if chunk.choices[0].delta.content is not None:
        print(chunk.choices[0].delta.content, end="")
```

### ğŸ”’ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ¨å¥¨

#### APIã‚­ãƒ¼ç®¡ç†
```python
import os
from openai import OpenAI

# âœ… ç’°å¢ƒå¤‰æ•°ã‚’ä½¿ç”¨ã—ã¦ã‚­ãƒ¼ã‚’ä¿å­˜
client = OpenAI(
    base_url="https://api.pandalla.ai/v1",
    api_key=os.getenv("OMNIAI_API_KEY")
)

# âŒ ã‚³ãƒ¼ãƒ‰ã«ã‚­ãƒ¼ã‚’ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã—ãªã„
# api_key="sk-hardcoded-key-in-code"  # å±é™ºï¼
```

#### ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
```python
# ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè£…
def safe_chat_completion(user_input):
    # å…¥åŠ›ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ãƒã‚§ãƒƒã‚¯
    if contains_sensitive_content(user_input):
        return {"error": "Content not allowed"}
    
    # æ­£å¸¸ãªAPIå‘¼ã³å‡ºã—
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": user_input}]
    )
    return response
```

---

## ã‚ˆãã‚ã‚‹è³ªå•

### â“ ä¸€èˆ¬çš„ãªã‚¨ãƒ©ãƒ¼å‡¦ç†

#### èº«å…ƒèªè¨¼å¤±æ•—
```python
try:
    response = client.chat.completions.create(...)
except Exception as e:
    if "401" in str(e):
        print("APIã‚­ãƒ¼ãŒç„¡åŠ¹ã§ã™ã€‚ã‚­ãƒ¼ãŒæ­£ã—ã„ã‹ç¢ºèªã—ã¦ãã ã•ã„")
    elif "403" in str(e):
        print("æ¨©é™ä¸è¶³ã§ã™ã€‚ã‚¢ã‚«ã‚¦ãƒ³ãƒˆæ®‹é«˜ã‚„æ¨©é™è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„")
```

#### ãƒ¢ãƒ‡ãƒ«åˆ©ç”¨ä¸å¯
```python
# ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆ¦ç•¥
def robust_chat_completion(messages, preferred_model="gpt-4o"):
    models = [preferred_model, "gpt-4o-mini", "gpt-3.5-turbo"]
    
    for model in models:
        try:
            return client.chat.completions.create(
                model=model, 
                messages=messages
            )
        except Exception as e:
            print(f"Model {model} failed: {e}")
            continue
    
    raise Exception("All models failed")
```

### ğŸ“ æŠ€è¡“ã‚µãƒãƒ¼ãƒˆ

å•é¡ŒãŒç™ºç”Ÿã—ãŸå ´åˆã¯ã„ã¤ã§ã‚‚ã‚µãƒãƒ¼ãƒˆã„ãŸã—ã¾ã™ï¼š

- ğŸ“§ **æŠ€è¡“ã‚µãƒãƒ¼ãƒˆãƒ¡ãƒ¼ãƒ«**: support@pandalla.ai
- ğŸ“± **ä¼æ¥­é¡§å®¢ãƒ›ãƒƒãƒˆãƒ©ã‚¤ãƒ³**: 24æ™‚é–“æŠ€è¡“ã‚µãƒãƒ¼ãƒˆå°‚ç”¨
- ğŸ“š **ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**: [https://docs.pandalla.ai](https://docs.pandalla.ai)
- ğŸ’¬ **ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãƒ•ã‚©ãƒ¼ãƒ©ãƒ **: [https://community.pandalla.ai](https://community.pandalla.ai)

---

ä»Šã™ãOmniAIã®ä½¿ç”¨ã‚’é–‹å§‹ã—ã¦ã€æœ€ã‚‚ä¾¿åˆ©ãªAIãƒ¢ãƒ‡ãƒ«ã‚¢ã‚¯ã‚»ã‚¹ã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½“é¨“ã—ã¦ãã ã•ã„ï¼